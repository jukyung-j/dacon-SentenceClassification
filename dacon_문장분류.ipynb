{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b3782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberta+lstm small = 0.2225\n",
    "# roberta+base+lstm  small= 0.234 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95232b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm, trange\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "# for graphing\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072069ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original = pd.read_csv('train.csv')\n",
    "# 중복 삭제\n",
    "train_original = train_original.loc[train_original.ID != 'TRAIN_14989']\n",
    "train_original = train_original.loc[train_original.ID != 'TRAIN_03364']\n",
    "train_original = train_original.loc[train_original.ID != 'TRAIN_07099']\n",
    "train_original = train_original.loc[train_original.ID != 'TRAIN_02108']\n",
    "train_original = train_original.drop_duplicates('문장', keep='first')\n",
    "train_original.drop(columns=['ID'], inplace=True)\n",
    "test = pd.read_csv('test.csv')\n",
    "test.drop(columns=['ID'], inplace=True)\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7995db",
   "metadata": {},
   "outputs": [],
   "source": [
    " tagger = [\n",
    "        \"NNG\", # 일반 명사\n",
    "        \"NNP\", # 고유 명사\n",
    "        \"NNB\", # 의존 명사\n",
    "        \"NNBC\", # 단위를 나타내는 명사\n",
    "        \"NR\", # 수사\n",
    "        \"NP\", # 대명사\n",
    "        \"VV\", # 동사\n",
    "        \"VA\", # 형용사\n",
    "        \"VX\", # 보조 용언\n",
    "        \"VCP\", # 긍정 지정사\n",
    "        \"VCN\",# 부정 지정사\n",
    "        \"MM\", # 관형사\n",
    "        \"MAG\", # 일반 부사\n",
    "        \"MAJ\", # 접속 부사\n",
    "        \"IC\", # 감탄사\n",
    "        \"JKC\",\n",
    "        \"JKS\", # 주격 조사\n",
    "        \"JKG\", # 관형격 조사\n",
    "        \"JKO\", # 목적격 조사\n",
    "        \"JKB\", # 부사격 조사\n",
    "        \"JKV\", # 호격 조사\n",
    "        \"JKQ\", # 인용격 조사\n",
    "        \"JX\", # 보조사\n",
    "        \"JC\", # 접속 조사\n",
    "        \"EP\", # 선어말 어미\n",
    "        \"EF\", # 종결 어미\n",
    "        \"EC\", # 연결 어미\n",
    "        \"ETN\", # 명사형 전성 어미\n",
    "        \"ETM\", # 관형형 전성 어미\n",
    "        \"XPN\", # 체언 접두사\n",
    "        \"XSN\", # 명사 파생 접미사\n",
    "        \"XSV\", # 동사 파생 접미사\n",
    "        \"XSA\", # 형용사 파생 접미사\n",
    "        \"XR\",  # 어근\n",
    "        'SF', # 마침표, 물음표, 느낌표\n",
    "        \"SE\", # 줄임표\n",
    "        \"SSO\", # 여는 괄호\n",
    "        \"SSC\", # 닫는 괄호\n",
    "        \"SC\", # 구분자\n",
    "        \"SY\",\n",
    "        \"SL\", # 외국어\n",
    "        \"SH\", # 한자\n",
    "        \"SN\", # 숫자\n",
    "         \"UNKNOWN\",\n",
    "         \"NA\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e3a57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "  random.seed(seed)\n",
    "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  torch.backends.cudnn.benchmark = True\n",
    "\n",
    "CFG = {\n",
    "    'EPOCHS':5,\n",
    "    'LEARNING_RATE':2e-5,\n",
    "    'BATCH_SIZE':2,\n",
    "    'SEED':42\n",
    "}\n",
    "\n",
    "seed_everything(CFG['SEED'])  # seed 고정\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b8978",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _, _ = train_test_split(train_original, train_original['label'], test_size = 0.2,random_state=CFG['SEED'])\n",
    "train = train.reset_index(drop=True)\n",
    "val = val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4542291",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'klue/roberta-small'\n",
    "base_model = AutoModel.from_pretrained(model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f8f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTypeDataset(Dataset):\n",
    "  def __init__(self, dataframe, tokenizer, labels=None):\n",
    "    texts = dataframe['문장'].values.tolist()\n",
    "\n",
    "    self.texts = [tokenizer(text, padding='max_length', max_length = 512, truncation=True, return_tensors='pt') for text in texts]\n",
    "    self.labels = labels\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.texts)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    text = self.texts[idx]\n",
    "    pos = self.input_pos[idx]\n",
    "    if self.labels is not None:\n",
    "      type_tmp = self.labels['type'][idx]\n",
    "      polarity_tmp = self.labels['polarity'][idx]\n",
    "      tense_tmp = self.labels['tense'][idx]\n",
    "      certainty_tmp = self.labels['certainty'][idx]\n",
    "      \n",
    "      return text, torch.Tensor(type_tmp), torch.Tensor(polarity_tmp), torch.Tensor(tense_tmp), torch.Tensor(certainty_tmp)\n",
    "    else:\n",
    "      return text, torch.Tensor([-1, -1, -1, -1]), torch.Tensor([-1, -1, -1]), torch.Tensor([-1, -1, -1]), torch.Tensor([-1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c07e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SentenceClassifier(nn.Module):\n",
    "  def __init__(self, base_model, input_size=768):\n",
    "    super().__init__()\n",
    "    self.roberta = base_model # from transformers package\n",
    "    hidden_size = self.roberta.config.hidden_size\n",
    "    # self.num_classes = num_classes\n",
    "    self.input_size = input_size\n",
    "    \n",
    "    # LSTM\n",
    "    self.BiLstm = nn.LSTM(input_size=768,\n",
    "                          hidden_size=320,\n",
    "                          num_layers=1,\n",
    "                          batch_first=True,\n",
    "                          bidirectional=True)\n",
    "    self.fc = nn.Sequential(nn.Dropout(0.5),\n",
    "                            nn.Linear(320 * 2, 32),\n",
    "                            nn.ReLU())\n",
    "    # 출력\n",
    "    self.type_clf = nn.Sequential(\n",
    "        nn.Dropout(p=0.3),\n",
    "        nn.Linear(in_features=32, out_features=4),\n",
    "    )\n",
    "    self.polarity_clf = nn.Sequential(\n",
    "        nn.Dropout(p=0.3),\n",
    "        nn.Linear(in_features=32, out_features=3),\n",
    "    )\n",
    "    self.tense_clf = nn.Sequential(\n",
    "        nn.Dropout(p=0.3),\n",
    "        nn.Linear(in_features=32, out_features=3),\n",
    "    )\n",
    "    self.certainty_clf = nn.Sequential(\n",
    "        nn.Dropout(p=0.3),\n",
    "        nn.Linear(in_features=32, out_features=2),\n",
    "    )\n",
    "    # self.type_clf = nn.Linear(32, 4)\n",
    "    # self.polarity_clf = nn.Linear(32, 3)\n",
    "    # self.tense_clf = nn.Linear(32, 3)\n",
    "    # self.certainty_clf = nn.Linear(32, 2)\n",
    "    # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask, pos_input):\n",
    "    klue_out = self.roberta(input_ids = input_ids, attention_mask = attention_mask)[0][:,0]\n",
    "#     out = self.roberta(input_ids = input_ids, attention_mask = attention_mask)\n",
    "#     cls_feats = out.last_hidden_state\n",
    "#     outputs = self.feature_extract(cls_feats)\n",
    "    outputs, _ = self.BiLstm(klue_out)\n",
    "    outputs = outputs[:, -1, :]\n",
    "    outputs = self.fc(outputs)\n",
    "\n",
    "\n",
    "    type_output = self.type_clf(outputs)\n",
    "    # type_output = self.softmax(type_output)\n",
    "    polarity_output = self.polarity_clf(outputs)\n",
    "    # polarity_output = self.softmax(polarity_output)\n",
    "    tense_output= self.tense_clf(outputs)\n",
    "    # tense_output = self.softmax(tense_output)\n",
    "    certainty_output = self.certainty_clf(outputs)\n",
    "    # certainty_output = self.softmax(certainty_output)\n",
    "\n",
    "    return type_output, polarity_output, tense_output, certainty_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f9e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def sentence_train(model, train_dataloader, val_dataloader, learning_rate, epochs, model_nm):\n",
    "    best_val_loss = 99999999999999\n",
    "    early_stopping_threshold_count = 0\n",
    "\n",
    "    criterion = {\n",
    "      'type': nn.CrossEntropyLoss().to(device),\n",
    "      'polarity': nn.CrossEntropyLoss().to(device),\n",
    "      'tense': nn.CrossEntropyLoss().to(device),\n",
    "      'certainty': nn.CrossEntropyLoss().to(device)\n",
    "  }\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_f1_train = 0\n",
    "        total_loss_train = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for train_input, type_label, polarity_label, tense_label, certainty_label in tqdm(train_dataloader):\n",
    "            attention_mask = train_input['attention_mask'].to(device)\n",
    "            input_ids = train_input['input_ids'].squeeze(1).to(device)\n",
    "            type_label = type_label.to(device)\n",
    "            polarity_label = polarity_label.to(device)\n",
    "            tense_label = tense_label.to(device)\n",
    "            certainty_label = certainty_label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            type_output, polarity_output, tense_output, certainty_output = model(input_ids, attention_mask) # from the forward function\n",
    "\n",
    "            loss = 0.25*criterion['type'](type_output, type_label.float()) + \\\n",
    "                    0.25*criterion['polarity'](polarity_output, polarity_label.float()) + \\\n",
    "                    0.25*criterion['tense'](tense_output, tense_label.float()) + \\\n",
    "                    0.25*criterion['certainty'](certainty_output, certainty_label.float())\n",
    "\n",
    "            total_loss_train += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():  # since we should not change gradient for validation\n",
    "            total_f1_val = 0\n",
    "            total_loss_val = 0\n",
    "            type_preds, polarity_preds, tense_preds, certainty_preds = [], [], [], []\n",
    "            type_labels, polarity_labels, tense_labels, certainty_labels = [], [], [], []\n",
    "            model.eval()\n",
    "\n",
    "          # same process as the above\n",
    "            for val_input, vtype_label, vpolarity_label, vtense_label, vcertainty_label in tqdm(val_dataloader):\n",
    "                attention_mask = val_input['attention_mask'].to(device)\n",
    "                input_ids = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                vtype_label = vtype_label.to(device)\n",
    "                vpolarity_label = vpolarity_label.to(device)\n",
    "                vtense_label = vtense_label.to(device)\n",
    "                vcertainty_label = vcertainty_label.to(device)\n",
    "                \n",
    "                vtype_output, vpolarity_output, vtense_output, vcertainty_output = model(input_ids, attention_mask) # from the forward function\n",
    "\n",
    "                loss = 0.25*criterion['type'](vtype_output, vtype_label.float()) + \\\n",
    "                    0.25*criterion['polarity'](vpolarity_output, vpolarity_label.float()) + \\\n",
    "                    0.25*criterion['tense'](vtense_output, vtense_label.float()) + \\\n",
    "                    0.25*criterion['certainty'](vcertainty_output, vcertainty_label.float())\n",
    "\n",
    "                total_loss_val += loss.item()\n",
    "\n",
    "        print(f\"Epochs:{epoch + 1} \"\n",
    "              f\"| Train Loss:{total_loss_train / len(train_dataloader): .3f}\"\n",
    "              f'| Val Loss: {total_loss_val / len(val_dataloader): .3f} '\n",
    "              )\n",
    "          # f'| 유형 F1: {type_f1:.5f} 극성 {polarity_f1:.5f} 시제 {tense_f1:.5f} 확실성 {certainty_f1:.5f}',)\n",
    "\n",
    "        if best_val_loss > total_loss_val:\n",
    "            best_val_loss = total_loss_val # saving only the best one\n",
    "            torch.save(model, f\"{model_nm}.pt\")\n",
    "            print(\"Saved model\")\n",
    "            early_stopping_threshold_count = 0\n",
    "        else:\n",
    "            early_stopping_threshold_count += 1 # checking how many epochs have passed that val_loss didn't increase\n",
    "\n",
    "        if early_stopping_threshold_count >= 2: # patience=1\n",
    "            print('Early stopping')\n",
    "            break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d193b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tmp = train[['문장', '유형', '극성', '시제', '확실성']]\n",
    "train_tmp = pd.get_dummies(train_tmp, columns=['유형', '극성', '시제', '확실성'])\n",
    "train_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e1b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_type = train_tmp.iloc[:, 1:5].values.tolist()\n",
    "train_polarity = train_tmp.iloc[:, 5:8].values.tolist()\n",
    "train_tense = train_tmp.iloc[:,8:11].values.tolist()\n",
    "train_certainty = train_tmp.iloc[:,11:13].values.tolist()\n",
    "\n",
    "train_labels = {\n",
    "    'type': train_type,\n",
    "    'polarity': train_polarity,\n",
    "    'tense': train_tense,\n",
    "    'certainty': train_certainty\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa2f4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tmp = val[['문장', '유형', '극성', '시제', '확실성']]\n",
    "val_tmp = pd.get_dummies(val_tmp, columns=['유형', '극성', '시제', '확실성'])\n",
    "\n",
    "val_type = val_tmp.iloc[:,1:5].values.tolist()\n",
    "val_polarity = val_tmp.iloc[:,5:8].values.tolist()\n",
    "val_tense = val_tmp.iloc[:,8:11].values.tolist()\n",
    "val_certainty = val_tmp.iloc[:,11:13].values.tolist()\n",
    "val_labels = {\n",
    "    'type': val_type,\n",
    "    'polarity': val_polarity,\n",
    "    'tense': val_tense,\n",
    "    'certainty': val_certainty\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c61d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(SentenceTypeDataset(train_tmp, tokenizer, train_labels), batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(SentenceTypeDataset(val_tmp, tokenizer, val_labels), batch_size=CFG['BATCH_SIZE'], num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f951d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceClassifier(base_model)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c5a209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de53bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b7fb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_train(model, train_dataloader, val_dataloader, CFG['LEARNING_RATE'], CFG['EPOCHS'], 'roberta+lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0d2832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_predictions(model, loader):\n",
    "  device = torch.device('cuda')\n",
    "  model = model.to(device)\n",
    "\n",
    "  type_probs, polarity_probs, tense_probs, clarity_probs = [], [], [], []\n",
    "  with torch.no_grad():\n",
    "    model.eval()\n",
    "    for data_input, _, _, _, _ in tqdm(loader):\n",
    "      attention_mask = data_input['attention_mask'].to(device)\n",
    "      input_ids = data_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "      type_output, polarity_output, tense_output, clarity_output = model(input_ids, attention_mask)\n",
    "      type_probs.append(type_output)\n",
    "      polarity_probs.append(polarity_output)\n",
    "      tense_probs.append(tense_output)\n",
    "      clarity_probs.append(clarity_output)\n",
    "\n",
    "  return torch.cat(type_probs).cpu().detach().numpy(), \\\n",
    "            torch.cat(polarity_probs).cpu().detach().numpy(), \\\n",
    "            torch.cat(tense_probs).cpu().detach().numpy(), \\\n",
    "            torch.cat(clarity_probs).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc4a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('roberta+lstm.pt')\n",
    "test_dataloader = DataLoader(SentenceTypeDataset(test, tokenizer), batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e2b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_type, test_pred_polarity, test_pred_tense, test_pred_certainty = get_type_predictions(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f9d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_type = ['대화형' if i==0 else '사실형' if i==1 else '예측형' if i==2 else '추론형' for i in [np.argmax(p) for p in test_pred_type]]\n",
    "test_polarity = ['긍정' if i==0 else '미정' if i==1 else '부정' for i in [np.argmax(p) for p in test_pred_polarity]]\n",
    "test_tense = ['과거' if i==0 else '미래' if i==1 else '현재' for i in [np.argmax(p) for p in test_pred_tense]]\n",
    "test_certainty = ['불확실' if i==0 else '확실' for i in [np.argmax(p) for p in test_pred_certainty]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca104440",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_sum = []\n",
    "for i in range(len(test_type)):\n",
    "    label_sum.append(f'{test_type[i]}-{test_polarity[i]}-{test_tense[i]}-{test_certainty[i]}')\n",
    "\n",
    "submission['label'] = label_sum\n",
    "submission.to_csv('roberta_feature_lstm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559eec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb44639e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
